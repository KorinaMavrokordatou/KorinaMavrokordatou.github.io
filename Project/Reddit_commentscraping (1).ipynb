{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reddit_commentscraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Ecgeto88IK"
      },
      "outputs": [],
      "source": [
        "!pip install praw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "VuzqHJKsMIyt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "am0Bx7vgMKpw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPTe1OQ0MODi",
        "outputId": "a0b3a0b0-7597-4076-f116-5eafbdad6964"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "XqFnQVdfMVfc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime"
      ],
      "metadata": {
        "id": "v8jV913l89_n"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date"
      ],
      "metadata": {
        "id": "5Wzhl69P7oqz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"6b1s-HdyLZWGFvxIXgVeZw\",\n",
        "    client_secret=\"vFmoF6sjog2YQh87xVxYCgvCJH648g\",\n",
        "    user_agent=\"korinamavr\",\n",
        ")"
      ],
      "metadata": {
        "id": "swgFKNYy9Cs_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reddit.read_only)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGq3PnaE9a0v",
        "outputId": "8fde04da-de57-4dca-f80d-0be6043b6393"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_posts = reddit.subreddit('BlackLivesMatter').top(limit=10)"
      ],
      "metadata": {
        "id": "aUSTil9y9hCY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_blob_sentiment(review, sub_entries_textblob):\n",
        "    analysis = TextBlob(review)\n",
        "    if analysis.sentiment.polarity >= 0.0001:\n",
        "        if analysis.sentiment.polarity > 0:\n",
        "            sub_entries_textblob['positive'] = sub_entries_textblob['positive'] + 1\n",
        "            return 'Positive'\n",
        "\n",
        "    elif analysis.sentiment.polarity <= -0.0001:\n",
        "        if analysis.sentiment.polarity <= 0:\n",
        "            sub_entries_textblob['negative'] = sub_entries_textblob['negative'] + 1\n",
        "            return 'Negative'\n",
        "    else:\n",
        "        sub_entries_textblob['neutral'] = sub_entries_textblob['neutral'] + 1\n",
        "        return 'Neutral'"
      ],
      "metadata": {
        "id": "VoVN1sD3TRbC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nltk_sentiment(review, sub_entries_nltk):\n",
        "    vs = sia.polarity_scores(review)\n",
        "    if not vs['neg'] > 0.05:\n",
        "        if vs['pos'] - vs['neg'] > 0:\n",
        "            sub_entries_nltk['positive'] = sub_entries_nltk['positive'] + 1\n",
        "            return 'Positive'\n",
        "        else:\n",
        "            sub_entries_nltk['neutral'] = sub_entries_nltk['neutral'] + 1\n",
        "            return 'Neutral'\n",
        "\n",
        "    elif not vs['pos'] > 0.05:\n",
        "        if vs['pos'] - vs['neg'] <= 0:\n",
        "            sub_entries_nltk['negative'] = sub_entries_nltk['negative'] + 1\n",
        "            return 'Negative'\n",
        "        else:\n",
        "            sub_entries_nltk['neutral'] = sub_entries_nltk['neutral'] + 1\n",
        "            return 'Neutral'\n",
        "    else:\n",
        "        sub_entries_nltk['neutral'] = sub_entries_nltk['neutral'] + 1\n",
        "        return 'Neutral'"
      ],
      "metadata": {
        "id": "rUKgxNOgTVi1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replies_of(top_level_comment, count_comment, sub_entries_textblob, sub_entries_nltk):\n",
        "    if len(top_level_comment.replies) == 0:\n",
        "        count_comment = 0\n",
        "        return\n",
        "    else:\n",
        "        for num, comment in enumerate(top_level_comment.replies):\n",
        "            try:\n",
        "                count_comment += 1\n",
        "                print('-' * count_comment, comment.body)\n",
        "                text_blob_sentiment(comment.body, sub_entries_textblob)\n",
        "                nltk_sentiment(comment.body, sub_entries_nltk)\n",
        "            except:\n",
        "                continue\n",
        "            replies_of(comment, count_comment, sub_entries_textblob,sub_entries_nltk)"
      ],
      "metadata": {
        "id": "GXtW3C3YTZ-c"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \n",
        "    for submission in top_posts:\n",
        "        sub_entries_textblob = {'negative': 0, 'positive' : 0, 'neutral' : 0}\n",
        "        sub_entries_nltk = {'negative': 0, 'positive' : 0, 'neutral' : 0}\n",
        "        print('Title of the post :', submission.title)\n",
        "        text_blob_sentiment(submission.title, sub_entries_textblob)\n",
        "        nltk_sentiment(submission.title, sub_entries_nltk)\n",
        "        print(\"\\n\")\n",
        "        submission_comm = reddit.submission(id=submission.id)\n",
        "\n",
        "        for count, top_level_comment in enumerate(submission_comm.comments):\n",
        "            print(f\"-------------{count} top level comment start--------------\")\n",
        "            count_comm = 0\n",
        "            try :\n",
        "                print(top_level_comment.body)\n",
        "                text_blob_sentiment(top_level_comment.body, sub_entries_textblob)\n",
        "                nltk_sentiment(top_level_comment.body, sub_entries_nltk)\n",
        "                replies_of(top_level_comment,\n",
        "                           count_comm,\n",
        "                           sub_entries_textblob,\n",
        "                           sub_entries_nltk)\n",
        "            except:\n",
        "                continue\n",
        "        print('Over all Sentiment of Topic by TextBlob :', sub_entries_textblob)\n",
        "        print('Over all Sentiment of Topic by VADER :', sub_entries_nltk)\n",
        "        print(\"\\n\\n\\n\")\n",
        "\n",
        "if __name__ == '__main__' :\n",
        "    main()"
      ],
      "metadata": {
        "id": "zZGsidLOTp2M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}